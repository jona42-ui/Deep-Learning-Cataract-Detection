{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c553bef3-7f96-403d-b0b6-a88cd957f3e6",
   "metadata": {},
   "source": [
    "# BSSE-24: DEEP LEARNING BASED CATARACT DIAGNOSIS MOBILE APP\n",
    "For now we want to get the Model ready!\n",
    "1. Preprocessing\n",
    "   The key here is a diverse, high quality, laballed dataset.\n",
    "   \n",
    "3. Model Input\n",
    "   \n",
    "   We will be utilizing the ResNet model architecture. its been trained on ImageNet-1k.\n",
    "   We will remove the top layers (e.g., fully connected layers) of the pre-trained model, as they are typically specific to the original classification task (e.g., ImageNet classification) and not relevant for feature extraction. So from our architecture, the Identified layer(s) in the pre-trained model that capture high-level features relevant to cataract detection will be examined. These layers are usually located towards the end of the network and before the classification layers. More on this in the experiment below.\n",
    "   \n",
    "5. Model Training/Fine-tuning\n",
    "6. Model Evaluation and Prediction\n",
    "\n",
    "## sample Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7777e9-b78e-4a7e-b38c-ba758a54de49",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import all necessary packages\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#!pip install --upgrade --force-reinstall tensorflow\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "# import all necessary packages\n",
    "#!pip install --upgrade --force-reinstall tensorflow\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25881ca3-8aba-4fb1-9fd2-3ca601f5f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_dir = \"../data\"\n",
    "output_dir = \"../data/preprocessed\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "513d38a9-ddab-43fb-ac39-e4d1e3f13d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image dimensions\n",
    "IMG_SIZE = (224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5871e996-ae0e-4e49-9eb8-ab369880da59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:22<00:00, 13.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess images\n",
    "for category in [\"1_normal\", \"2_cataract\"]:\n",
    "    category_dir = os.path.join(data_dir, category)\n",
    "    output_category_dir = os.path.join(output_dir, category)\n",
    "    os.makedirs(output_category_dir, exist_ok=True)\n",
    "    \n",
    "    for img_name in tqdm(os.listdir(category_dir)):\n",
    "        img_path = os.path.join(category_dir, img_name)\n",
    "        output_img_path = os.path.join(output_category_dir, img_name)\n",
    "        \n",
    "        # Open image\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        # Resize image\n",
    "        img_resized = img.resize(IMG_SIZE)\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        img_gray = img_resized.convert('L')\n",
    "        \n",
    "        # Save preprocessed image\n",
    "        img_gray.save(output_img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a59bac5-e06b-4c3e-9d34-153d4a6ccf5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
