{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe77349-c1d2-4b91-896e-be719111396f",
   "metadata": {},
   "source": [
    "# Optimize the model Size and Performance for mobile platforms\n",
    "\n",
    "\n",
    "The objective of this notebook is to convert the pytorch model to format compatible to mobile platforms.\n",
    "1. convert the PyTorch model to ONNX format\n",
    "   \n",
    "   ONNX (Open Neural Network Exchange) is open format for exchange of Deep Learning model between different Frameworks. In other words it is format which is widely used for exchanging one model from one framework to other framework. We will first convert model from Pytorch to ONNX so we can transfer it to another framework.\n",
    "The Process of converting to ONNX is that we make a random dummy input and pass it through the model in pytorch and then pass it throught the function of onnx export to export it to a .onnx file. The shape of the dummy input should be (1, shape of single images) in detail the input would be (1, number of color channels, width of picture , height of picture )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f40b36b-98c3-4d4b-b822-bf1da5b41539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for this notebook\n",
    "def gvd(variable):\n",
    "    print(\"The data type of this variable is \" + str(type(variable)))\n",
    "import time\n",
    "def mills():\n",
    "    return int(round(time.time() * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26487765-a98e-49cc-8e8e-b6cae0fc2adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6565c2-804a-47cb-ae46-60441df3254b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thembo/college/cataract/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/thembo/college/cataract/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export time: 3.272263526916504 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the trained PyTorch model\n",
    "model = models.resnet152(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "out_ftrs = 2  # Binary classification\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(num_ftrs, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, out_ftrs),\n",
    "    torch.nn.LogSoftmax(dim=1)\n",
    ")\n",
    "model.load_state_dict(torch.load('final_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Example input with batch size of 1\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export the model to ONNX format with optimizations\n",
    "start_time = time.time()\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    dummy_input, \n",
    "    \"model.onnx\", \n",
    "    verbose=False, \n",
    "    export_params=True, \n",
    "    do_constant_folding=True\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Export time: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab3b03b-001f-47fe-b0ba-efda97561093",
   "metadata": {},
   "source": [
    "\n",
    "## Run ONNX model with ONNX runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12b9bc59-7b03-43d6-949a-d32c0792a94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model single inference in milliSeconds on onnxruntime 88\n",
      "Output [array([[-0.5618211, -0.844365 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as nxrun\n",
    "\n",
    "sess = nxrun.InferenceSession('./model.onnx')\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "start_time = mills()\n",
    "# run onnx model with onnx runtime python\n",
    "result = sess.run(None, {input_name: dummy_input.numpy()})\n",
    "\n",
    "end_time = mills()\n",
    "print(\"model single inference in milliSeconds on onnxruntime\", end_time - start_time)\n",
    "print(\"Output\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6deee67-3f41-4595-87e2-487054b7710d",
   "metadata": {},
   "source": [
    "## Convert from ONNX to TensorFlow FreezeGraph\n",
    "\n",
    "\n",
    "We will use onnx-tf to convert model\n",
    "\n",
    "onnx_tf is the library build by onnx team which is used to transfer the model from onnx to tensorflow it can create a backend to enable the model to run with tensorflow. We will first load the saved .onnx model file with onnx.load and the by using prepare function of onnx_tf prepare that loaded model to be run by tensorflow. and by using the export_graph function of that prepared backend we can export this model in a file format with .tf extension supported by Original Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3ada84a-4aae-4bf5-af25-1580dec09a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Requirement already satisfied: numpy>=1.20 in /home/thembo/college/cataract/lib/python3.9/site-packages (from onnx) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/thembo/college/cataract/lib/python3.9/site-packages (from onnx) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/thembo/college/cataract/lib/python3.9/site-packages (from onnx>=1.5.0->onnx-tf==1.5.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/thembo/college/cataract/lib/python3.9/site-packages (from onnx>=1.5.0->onnx-tf==1.5.0) (3.20.3)\n"
     ]
    }
   ],
   "source": [
    "# install onnx and onnx-tf\n",
    "!pip install --upgrade onnx | tail -n 2\n",
    "!pip install  onnx-tf==1.5.0 | tail -n 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19fea8b8-79fc-4a38-993b-db02ebfec275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow                    2.5.0\n",
      "tensorflow-addons             0.23.0\n",
      "tensorflow-cpu                2.16.1\n",
      "tensorflow-datasets           4.9.3\n",
      "tensorflow-estimator          2.5.0\n",
      "tensorflow-hub                0.16.1\n",
      "tensorflow-io-gcs-filesystem  0.37.0\n",
      "tensorflow-metadata           1.15.0\n",
      "tensorflow-model-optimization 0.8.0\n",
      "tensorflow-probability        0.24.0\n",
      "tensorflow-text               2.15.0\n"
     ]
    }
   ],
   "source": [
    "# see versions of all tensorflow libraries installed\n",
    "!pip list | grep 'flow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aae46cab-d4cb-42ad-a21c-705722a62b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33e6f249-0d09-4f25-ba31-ef7e45a0d18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-30 10:54:57.200026: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-30 10:54:57.200051: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/thembo/college/cataract/lib/python3.9/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py:37: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.19.5)\n",
      "  from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top\n",
      "/home/thembo/college/cataract/lib/python3.9/site-packages/onnx_tf/common/__init__.py:89: UserWarning: onnx_tf.common.get_outputs_names is deprecated. It will be removed in future release. Use TensorflowGraph.get_outputs_names instead.\n",
      "  warnings.warn(message)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thembo/college/cataract/bin/onnx-tf\", line 5, in <module>\n",
      "    from onnx_tf.cli import main\n",
      "  File \"/home/thembo/college/cataract/lib/python3.9/site-packages/onnx_tf/__init__.py\", line 1, in <module>\n",
      "    from . import backend\n",
      "  File \"/home/thembo/college/cataract/lib/python3.9/site-packages/onnx_tf/backend.py\", line 29, in <module>\n",
      "    from onnx_tf.common.handler_helper import get_all_backend_handlers\n",
      "  File \"/home/thembo/college/cataract/lib/python3.9/site-packages/onnx_tf/common/handler_helper.py\", line 5, in <module>\n",
      "    from onnx_tf.handlers.backend import *  # noqa\n",
      "  File \"/home/thembo/college/cataract/lib/python3.9/site-packages/onnx_tf/handlers/backend/ceil.py\", line 10, in <module>\n",
      "    @tf_func(tf.ceil)\n",
      "AttributeError: module 'tensorflow' has no attribute 'ceil'\n"
     ]
    }
   ],
   "source": [
    "!onnx-tf convert -i \"./model.onnx\" -o  './final_model.pb' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1aacf4d3-4ca2-421c-8962-1d614c1dea2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load the model saved in onnx format\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prepare\n\u001b[1;32m      4\u001b[0m model_onnx \u001b[38;5;241m=\u001b[39m onnx\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.onnx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m onnx\u001b[38;5;241m.\u001b[39mchecker\u001b[38;5;241m.\u001b[39mcheck_model(model_onnx)\n",
      "File \u001b[0;32m~/college/cataract/lib/python3.9/site-packages/onnx_tf/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[0;32m~/college/cataract/lib/python3.9/site-packages/onnx_tf/backend.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_unique_suffix\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m supports_device \u001b[38;5;28;01mas\u001b[39;00m common_supports_device\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandler_helper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_all_backend_handlers\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpb_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OnnxNode\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\n",
      "File \u001b[0;32m~/college/cataract/lib/python3.9/site-packages/onnx_tf/common/handler_helper.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defs\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendHandler\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_backend_handlers\u001b[39m(opset_dict):\n",
      "File \u001b[0;32m~/college/cataract/lib/python3.9/site-packages/onnx_tf/handlers/backend/hardmax.py:10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m onnx_op\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_func\n\u001b[1;32m      9\u001b[0m \u001b[38;5;129m@onnx_op\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHardmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;129m@tf_func\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrib\u001b[49m\u001b[38;5;241m.\u001b[39mseq2seq\u001b[38;5;241m.\u001b[39mhardmax)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mHardmax\u001b[39;00m(BackendHandler):\n\u001b[1;32m     13\u001b[0m   \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     14\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_common\u001b[39m(\u001b[38;5;28mcls\u001b[39m, node, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m][node\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "# load the model saved in onnx format\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "model_onnx = onnx.load('model.onnx')\n",
    "onnx.checker.check_model(model_onnx)\n",
    "\n",
    "# prepare model for exporting to tensorFlow using tensorFlow backend\n",
    "tf_rep = prepare(model_onnx)\n",
    "start_time = mills()\n",
    "print(tf_rep.run(dummy_input))\n",
    "end_time = mills()\n",
    "print(end_time - start_time)\n",
    "print(tf_rep.inputs) # Input nodes to the model\n",
    "print('-----')\n",
    "print(tf_rep.outputs) # Output nodes from the model\n",
    "print('-----')\n",
    "print(tf_rep.tensor_dict) # All nodes in the model\n",
    "\n",
    "# # export tensorFlow backend to tensorflow tf file\n",
    "tf_rep.export_graph('final_model.pb')\n",
    "tf_rep.run(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adc5f44-6ad1-4c6c-b147-978ff6aa9cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
